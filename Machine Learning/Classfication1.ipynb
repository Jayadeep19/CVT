{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689463c5-758b-4fe3-94ff-27da21b51cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78821f8-a78b-4efc-a398-7ccd41f95389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for files in os.listdir('./train'):\n",
    "    c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3209d8-7c10-4485-901c-ec096118c9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', '0', 'jpg']\n"
     ]
    }
   ],
   "source": [
    "txt = \"cat.0.jpg\"\n",
    "\n",
    "x = txt.split(\".\")\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8366d16b-443d-43f6-a5a8-ba706900348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for files in os.listdir('./train'):\n",
    "    image = cv.imread(os.path.join('./train', files))\n",
    "    image_resize = cv.resize(image,(100,100))\n",
    "    gray = cv.cvtColor(image_resize, cv.COLOR_RGB2GRAY)\n",
    "    label = files.split('.')[0]\n",
    "    if label == 'cat':\n",
    "        data.append([gray, np.array([0])])\n",
    "    if label == 'dog':\n",
    "        data.append([gray, np.array([1])])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c07ceb7-9cb4-4f17-bd92-6c32973f41d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[146, 152, 155, ..., 189, 185, 183],\n",
      "       [146, 152, 155, ..., 192, 187, 184],\n",
      "       [146, 152, 155, ..., 196, 188, 186],\n",
      "       ...,\n",
      "       [108, 110, 113, ...,   3,   3,   1],\n",
      "       [108, 109, 112, ...,   2,   2,   2],\n",
      "       [104, 106, 110, ...,   1,   1,   1]], dtype=uint8), array([0])], [array([[ 43,  45,  45, ...,  95, 179, 186],\n",
      "       [ 40,  38,  40, ..., 105, 173, 187],\n",
      "       [ 43,  38,  42, ...,  93, 170, 189],\n",
      "       ...,\n",
      "       [ 21,  20,  20, ...,  81,  70,  38],\n",
      "       [ 24,  18,  21, ...,  55,  35,  26],\n",
      "       [ 29,  20,  24, ...,  85,  15,  32]], dtype=uint8), array([0])], [array([[ 41,  28,  46, ..., 157, 158, 154],\n",
      "       [ 45,  55,  61, ..., 157, 160, 156],\n",
      "       [ 54,  59,  61, ..., 159, 162, 158],\n",
      "       ...,\n",
      "       [145, 146, 145, ..., 133, 136, 125],\n",
      "       [159, 151, 142, ..., 134, 137, 125],\n",
      "       [132, 115, 123, ..., 134, 136, 122]], dtype=uint8), array([0])]]\n"
     ]
    }
   ],
   "source": [
    "print(data[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a5a8147-2df1-42fd-9329-80912f990e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the best practice is to shuffel the data so that the model would be robust\n",
    "import random\n",
    "\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf0d27e7-282d-4fba-be32-84ca67c8da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for features,labels in data:\n",
    "    x.append(features)\n",
    "    y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d04b28-2b82-453d-b3a6-f0aa47c510e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4401eb6-a127-476b-86a3-2a8e7108b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "#It would be much more easy for the computation if the values of the features are in the range between 0 and 1\n",
    "x = x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d65af51-1e13-4f1b-8c6b-d955724f8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(x))\n",
    "print(len(x))\n",
    "print(x.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab8525-96d0-4ebb-b43a-fa5da36931de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4bb6fbd-c1f1-48e8-b755-d97291c2da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(-1, 100, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d4b4fb6-de32-445d-b748-673dc846778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "309393ab-91a5-4744-8a87-1d4f52ad2959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTo open the pickel files again use the load function\\n\\nvariable = joblib.load('filename.format')\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Resizing the data and training the model on huge datasets can be time consuming and computation expensive\n",
    "So, the best way to use the model again is to save the training weights and to reuse the model without\n",
    "actually training the model again.\n",
    "\n",
    "There are many libraries to save files\n",
    "I used 'joblib' as it is efficient in handling arrays\n",
    "'''\n",
    "\n",
    "joblib.dump(x, 'features.pkl')\n",
    "joblib.dump(y, 'labels.pkl')\n",
    "\n",
    "'''\n",
    "To open the pickel files again use the load function\n",
    "\n",
    "variable = joblib.load('filename.format')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e212487-883f-4b04-ab15-68831f00a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now that the data is prepared and sorted, we need to create the model with desired number of convolution\n",
    "layers, pooling layers, and fully connected layers with desired number of filters and their sizes\n",
    "'''\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu', input_shape = x.shape[1:]))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, input_shape = x.shape[1:], activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64a799c1-fdba-4fce-bb26-e7f1762dc2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We need to define the optimisers and loss functions\n",
    "optimisers are primarly use to define the learning rate for indivudual parameters\n",
    "Loss function is the actual difference of the actual label and predicted label which has to be minimized\n",
    "'''\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b904fc76-f1eb-44b6-8648-e315fb015cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "704/704 [==============================] - 320s 454ms/step - loss: 0.6627 - accuracy: 0.5896 - val_loss: 0.5803 - val_accuracy: 0.6932\n",
      "Epoch 2/3\n",
      "704/704 [==============================] - 310s 441ms/step - loss: 0.5276 - accuracy: 0.7362 - val_loss: 0.4818 - val_accuracy: 0.7728\n",
      "Epoch 3/3\n",
      "704/704 [==============================] - 313s 444ms/step - loss: 0.4399 - accuracy: 0.7953 - val_loss: 0.4172 - val_accuracy: 0.8040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2031fa7ebe0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x ,y, epochs = 3, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224fd32-9721-4e11-8bb1-2006d6598e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
